#!/bin/bash
info()
{
    echo '[INFO] ' "$@"
}

infoL()
{
    echo -en '[INFO] ' "$@\n"
}

sleep_cursor()
{
 chars="/-\|"
 for (( z=0; z<7; z++ )); do
   for (( i=0; i<${#chars}; i++ )); do
    sleep 0.5
    echo -en "${chars:$i:1}" "\r"
  done
done
}


wait() 
{
status=1
infoL "Testing.." $1.$2  
while [ : ]
  do
    sleep_cursor &
    kubectl wait --for condition=available --timeout=14s deploy -l  $1   -n $2
    status=$?
    
    if [ $status -ne 0 ]
    then 
      infoL "$1 isn't ready yet. This may take a few minutes..."
      sleep_cursor
    else
      break  
    fi 
  done
}

k3s_install()
{
curl -sfL https://get.k3s.io | sh -s - --write-kubeconfig-mode 644
}

k3s_install_gpu()
{
curl -sfL https://get.k3s.io | sh -s - --docker --kubelet-arg="feature-gates=DevicePlugins=true" --write-kubeconfig-mode 644
#### GPU Support
kubectl create -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v0.7.0/nvidia-device-plugin.yml
}

kf_pipeline()
{
  curl -sfL https://get.k3s.io | sh -s - --write-kubeconfig-mode 644
        

        info "Installing pipelines crd"
        export PIPELINE_VERSION=1.0.1
        kubectl apply -k "github.com/kubeflow/pipelines/manifests/kustomize/cluster-scoped-resources?ref=$PIPELINE_VERSION"
        kubectl wait --for condition=established --timeout=60s crd/applications.app.k8s.io
        sleep_cursor &
        info "Installing pipelines manifests"
        kubectl apply -k "github.com/kubeflow/pipelines/manifests/kustomize/env/platform-agnostic-pns?ref=$PIPELINE_VERSION"

        waiting_pod_array=("k8s-app=kube-dns;kube-system" 
                        "k8s-app=metrics-server;kube-system"
                        "app=traefik;kube-system"  
                        "app=minio;kubeflow"
                        "app=mysql;kubeflow"
                        "app=cache-server;kubeflow"
                        "app=ml-pipeline-persistenceagent;kubeflow"
                        "component=metadata-grpc-server;kubeflow"
                        "app=ml-pipeline-ui;kubeflow")

        for i in "${waiting_pod_array[@]}"; do 
        echo "$i"; 
        IFS=';' read -ra VALUES <<< "$i"
            wait "${VALUES[0]}" "${VALUES[1]}"
        done


        info "Kubeflow pipelines ready!!"

        info "Defining the ingress"
        sleep_cursor
}

triton_cpu()
{
curl https://raw.githubusercontent.com/helm/helm/master/scripts/get | bash
kubectl create serviceaccount -n kube-system tiller
kubectl create clusterrolebinding tiller-cluster-rule --clusterrole=cluster-admin --serviceaccount=kube-system:tiller
helm init --service-account tiller --wait
#Install minio
helm repo add minio https://helm.min.io/
helm install --namespace minio --generate-name minio/minio --set defaultBucket.enabled=true --set defaultBucket.name=triton_models


#Install prometheus
helm install --name triton-metrics --set prometheus.prometheusSpec.serviceMonitorSelectorNilUsesHelmValues=false stable/prometheus-operator

#Install Triton
helm install --name triton /inference/triton/cpu/

}

 kf_ingress()
{
kubectl apply -f - << EOF 
apiVersion: networking.k8s.io/v1beta1
kind: IngressClass
metadata: 
    name: traefik-lb
spec: 
    controller: traefik.io/ingress-controller
EOF

        kubectl apply -f - << EOF
apiVersion: "networking.k8s.io/v1beta1"
kind: "Ingress"
metadata:
    name: "example-ingress"
    namespace: kubeflow
    annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /$2
    
spec:
    ingressClassName: "traefik-lb"
    rules:
    - http:
        paths:
        - path: "/"
        backend:
            serviceName: "ml-pipeline-ui"
            servicePort: 80
EOF
}


while test $# -gt 0; do
  case "$1" in
    --gpu)
      info "Install NVIDIA gpu operator"
      k3s_install_gpu 
      export KUBECONFIG=/etc/rancher/k3s/k3s.yaml
      ;;
    --triton-cpu)
      info "Installing NVIDIA Triton Inference Server  - CPU only"
      k3s_install
      export KUBECONFIG=/etc/rancher/k3s/k3s.yaml
      triton_cpu
    ;;
    --triton)
      info "Installing NVIDIA Triton Inference Server - GPU supported"
      k3s_install_gpu
      export KUBECONFIG=/etc/rancher/k3s/k3s.yaml
    ;;
    --tf)
      curl -sfL https://get.k3s.io | sh -s - --write-kubeconfig-mode 644
      export KUBECONFIG=/etc/rancher/k3s/k3s.yaml
    ;;
    --pipelines)
      info "Installing Kubeflow pipelines - CPU only"
      k3s_install
      export KUBECONFIG=/etc/rancher/k3s/k3s.yaml
      kf_pipeline
      kf_ingress     
    ;;
    --pipelines-gpu)
      info "Installing Kubeflow pipelines - CPU only"
      k3s_install_gpu
      export KUBECONFIG=/etc/rancher/k3s/k3s.yaml
      kf_pipeline
      kf_ingress     
    ;;
    --tekton)
    ;;
    --kubeflow)
    ;;
    --argo)
    ;;
    *)
    break
    ;;
 esac
 done
